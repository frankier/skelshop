{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is this? This is the documentation for SkelShop . See also the README there for a little bit of extra background. Feel free to ask in the issues for help. Getting started There are 3 options: A Docker container, recommended for general usage. A Singularity container, for HPC environments. Manual setup, which may be convenient for development of SkelShop, usage as a library, or if you want to use GUI components such as the playsticks command. (It may also be possible to run playsticks with x11docker . Please let me know if you get this working so I can add it to these instructions.) You may find it easiest to combine these, e.g. dump skeletons from one of the container, while only running playsticks with the manual installation. Docker container There are two Docker containers, one based on CUDA and one able to run (slowly...) using only a CPU. For the CUDA (10.2) version, make sure you have CUDA 10 and nvidia-docker on the host and then run: $ docker run --nv frankierr/skelshop:focal_nvcaffe python -m skelshop --help For the CPU version: $ docker run frankierr/skelshop:focal_cpu python -m skelshop --help For more information about the Docker containers see their page on Docker Hub and the openpose_containers repository where the bases are built . Singularity container There is a GPU Singularity container. Run it like so: $ singularity run --nv shub://frankier/skelshop:latest python -m skelshop --help Manual setup You need to install Poetry and OpenPose v1.7.0 . $ ./install_all.sh $ poetry run snakemake If you only want to run the playsticks command you do not need to install OpenPose, can instead run $ ./install.sh -E playsticks","title":"Getting started"},{"location":"#what-is-this","text":"This is the documentation for SkelShop . See also the README there for a little bit of extra background. Feel free to ask in the issues for help.","title":"What is this?"},{"location":"#getting-started","text":"There are 3 options: A Docker container, recommended for general usage. A Singularity container, for HPC environments. Manual setup, which may be convenient for development of SkelShop, usage as a library, or if you want to use GUI components such as the playsticks command. (It may also be possible to run playsticks with x11docker . Please let me know if you get this working so I can add it to these instructions.) You may find it easiest to combine these, e.g. dump skeletons from one of the container, while only running playsticks with the manual installation.","title":"Getting started"},{"location":"#docker-container","text":"There are two Docker containers, one based on CUDA and one able to run (slowly...) using only a CPU. For the CUDA (10.2) version, make sure you have CUDA 10 and nvidia-docker on the host and then run: $ docker run --nv frankierr/skelshop:focal_nvcaffe python -m skelshop --help For the CPU version: $ docker run frankierr/skelshop:focal_cpu python -m skelshop --help For more information about the Docker containers see their page on Docker Hub and the openpose_containers repository where the bases are built .","title":"Docker container"},{"location":"#singularity-container","text":"There is a GPU Singularity container. Run it like so: $ singularity run --nv shub://frankier/skelshop:latest python -m skelshop --help","title":"Singularity container"},{"location":"#manual-setup","text":"You need to install Poetry and OpenPose v1.7.0 . $ ./install_all.sh $ poetry run snakemake If you only want to run the playsticks command you do not need to install OpenPose, can instead run $ ./install.sh -E playsticks","title":"Manual setup"},{"location":"cli/","text":"CLI Reference skelshop Usage: skelshop [OPTIONS] COMMAND [ARGS]... Options: -v, --verbosity LVL Either CRITICAL, ERROR, WARNING, INFO or DEBUG --ffprobe-bin PATH If you cannot install ffprobe globally, you can provide the path to the version you want to use here bench Commands to benchmark SkelShop's I/O speeds. Usage: skelshop bench [OPTIONS] COMMAND [ARGS]... read-shot-seg Benchmark reading a shot segmented skeleton file. Usage: skelshop bench read-shot-seg [OPTIONS] SKELS_FN calibrate Keypoint calibration tools. Usage: skelshop calibrate [OPTIONS] COMMAND [ARGS]... analyse Usage: skelshop calibrate analyse [OPTIONS] DFIN [CHARTOUT] process-dlib-dir Give a directory with dlib facepoint XMLs, run OpenPose on all images and write out where the keypoints are relative to the chips. Usage: skelshop calibrate process-dlib-dir [OPTIONS] DIRIN H5IN DFOUT process-video Given a video and a skeleton keypoint file, run the dlib keypoint detection pipeline for each frame and give points where BODY_25 face keypoints would have to map to make the same transformation. Usage: skelshop calibrate process-video [OPTIONS] VIDEO H5INFN DFOUT conv Convert a exiting dump from another format into HDF5 format. LEGACY_DUMP is the dump in the old format. OUT is a file path when run with single-zip, otherwise it is the base of a directory tree which will be created during processing. Usage: skelshop conv [OPTIONS] [monolithic-tar|single-zip|ordered-tar] LEGACY_DUMP [OUT] Options: --mode [BODY_25_ALL|BODY_25_HANDS|BODY_25|BODY_135|FACE|BODY_25_FACE] [required] --cores INTEGER Number of cores to use (only for monolithic- tar) --suppress-end-fail / --no-suppress-end-fail --skip-existing / --overwrite-existing drawsticks Output a video with stick figures from pose dump superimposed. Usage: skelshop drawsticks [OPTIONS] H5FN VIDEOIN VIDEOOUT Options: --posetrack / --no-posetrack Whether to convert BODY_25 keypoints to PoseTrack-style keypoints --scale INTEGER --overlay / --no-overlay Whether to draw VIDEOIN below the stick figures or not dump Create a HDF5 pose dump from a video using OpenPose. This command optionally applies steps from the tracking/segmentation pipeline. Usage: skelshop dump [OPTIONS] VIDEO H5FN Options: --mode [BODY_25_ALL|BODY_25_HANDS|BODY_25|BODY_135|FACE|BODY_25_FACE] --model-folder TEXT [required] --debug / --no-debug --dry-run / --write --segs-file PATH --pose-matcher-config TEXT --track-conf [lighttrackish|opt_lighttrack|deepsortlike] --track / --no-track --shot-seg [bbskel|psd|ffprobe|none] dumpimgs Dump a directory of images to a HDF5 file using OpenPose. Usage: skelshop dumpimgs [OPTIONS] INPUT_DIR H5OUT Options: --mode [BODY_25_ALL|BODY_25_HANDS|BODY_25|BODY_135|FACE|BODY_25_FACE] --model-folder TEXT [required] face Create a HDF5 face dump from a video using dlib. Usage: skelshop face [OPTIONS] VIDEO H5FN Options: --from-skels PATH --start-frame INTEGER --skel-thresh-pool [min|max|mean] --skel-thresh-val FLOAT --batch-size INTEGER --write-bbox / --no-write-bbox --write-chip / --no-write-chip filter Apply tracking to an untracked HDF5 pose dump. Usage: skelshop filter [OPTIONS] H5INFN H5OUTFN Options: --segs-file PATH --pose-matcher-config TEXT --track-conf [lighttrackish|opt_lighttrack|deepsortlike] --track / --no-track --shot-seg [bbskel|psd|ffprobe|none] --start-frame INTEGER --end-frame INTEGER idsegs Identifying shots with a particular person from reference headshots and optionally get their bbox within the whole shot. Usage: skelshop idsegs [OPTIONS] REFIN SKELIN FACEIN SEGSOUT Options: --scene-bboxes / --no-scene-bboxes playsticks Play a video with stick figures from pose dump superimposed. Usage: skelshop playsticks [OPTIONS] VIDEOIN Options: --skel PATH --face PATH --posetrack / --no-posetrack Whether to convert BODY_25 keypoints to PoseTrack-style keypoints --seek-time FLOAT --seek-frame INTEGER --scale INTEGER --paused / --playing stats Output stats about dumps in INPUT_DIR. Usage: skelshop stats [OPTIONS] INPUT_DIR","title":"CLI reference"},{"location":"cli/#cli-reference","text":"","title":"CLI Reference"},{"location":"cli/#skelshop","text":"Usage: skelshop [OPTIONS] COMMAND [ARGS]... Options: -v, --verbosity LVL Either CRITICAL, ERROR, WARNING, INFO or DEBUG --ffprobe-bin PATH If you cannot install ffprobe globally, you can provide the path to the version you want to use here","title":"skelshop"},{"location":"cli/#bench","text":"Commands to benchmark SkelShop's I/O speeds. Usage: skelshop bench [OPTIONS] COMMAND [ARGS]...","title":"bench"},{"location":"cli/#read-shot-seg","text":"Benchmark reading a shot segmented skeleton file. Usage: skelshop bench read-shot-seg [OPTIONS] SKELS_FN","title":"read-shot-seg"},{"location":"cli/#calibrate","text":"Keypoint calibration tools. Usage: skelshop calibrate [OPTIONS] COMMAND [ARGS]...","title":"calibrate"},{"location":"cli/#analyse","text":"Usage: skelshop calibrate analyse [OPTIONS] DFIN [CHARTOUT]","title":"analyse"},{"location":"cli/#process-dlib-dir","text":"Give a directory with dlib facepoint XMLs, run OpenPose on all images and write out where the keypoints are relative to the chips. Usage: skelshop calibrate process-dlib-dir [OPTIONS] DIRIN H5IN DFOUT","title":"process-dlib-dir"},{"location":"cli/#process-video","text":"Given a video and a skeleton keypoint file, run the dlib keypoint detection pipeline for each frame and give points where BODY_25 face keypoints would have to map to make the same transformation. Usage: skelshop calibrate process-video [OPTIONS] VIDEO H5INFN DFOUT","title":"process-video"},{"location":"cli/#conv","text":"Convert a exiting dump from another format into HDF5 format. LEGACY_DUMP is the dump in the old format. OUT is a file path when run with single-zip, otherwise it is the base of a directory tree which will be created during processing. Usage: skelshop conv [OPTIONS] [monolithic-tar|single-zip|ordered-tar] LEGACY_DUMP [OUT] Options: --mode [BODY_25_ALL|BODY_25_HANDS|BODY_25|BODY_135|FACE|BODY_25_FACE] [required] --cores INTEGER Number of cores to use (only for monolithic- tar) --suppress-end-fail / --no-suppress-end-fail --skip-existing / --overwrite-existing","title":"conv"},{"location":"cli/#drawsticks","text":"Output a video with stick figures from pose dump superimposed. Usage: skelshop drawsticks [OPTIONS] H5FN VIDEOIN VIDEOOUT Options: --posetrack / --no-posetrack Whether to convert BODY_25 keypoints to PoseTrack-style keypoints --scale INTEGER --overlay / --no-overlay Whether to draw VIDEOIN below the stick figures or not","title":"drawsticks"},{"location":"cli/#dump","text":"Create a HDF5 pose dump from a video using OpenPose. This command optionally applies steps from the tracking/segmentation pipeline. Usage: skelshop dump [OPTIONS] VIDEO H5FN Options: --mode [BODY_25_ALL|BODY_25_HANDS|BODY_25|BODY_135|FACE|BODY_25_FACE] --model-folder TEXT [required] --debug / --no-debug --dry-run / --write --segs-file PATH --pose-matcher-config TEXT --track-conf [lighttrackish|opt_lighttrack|deepsortlike] --track / --no-track --shot-seg [bbskel|psd|ffprobe|none]","title":"dump"},{"location":"cli/#dumpimgs","text":"Dump a directory of images to a HDF5 file using OpenPose. Usage: skelshop dumpimgs [OPTIONS] INPUT_DIR H5OUT Options: --mode [BODY_25_ALL|BODY_25_HANDS|BODY_25|BODY_135|FACE|BODY_25_FACE] --model-folder TEXT [required]","title":"dumpimgs"},{"location":"cli/#face","text":"Create a HDF5 face dump from a video using dlib. Usage: skelshop face [OPTIONS] VIDEO H5FN Options: --from-skels PATH --start-frame INTEGER --skel-thresh-pool [min|max|mean] --skel-thresh-val FLOAT --batch-size INTEGER --write-bbox / --no-write-bbox --write-chip / --no-write-chip","title":"face"},{"location":"cli/#filter","text":"Apply tracking to an untracked HDF5 pose dump. Usage: skelshop filter [OPTIONS] H5INFN H5OUTFN Options: --segs-file PATH --pose-matcher-config TEXT --track-conf [lighttrackish|opt_lighttrack|deepsortlike] --track / --no-track --shot-seg [bbskel|psd|ffprobe|none] --start-frame INTEGER --end-frame INTEGER","title":"filter"},{"location":"cli/#idsegs","text":"Identifying shots with a particular person from reference headshots and optionally get their bbox within the whole shot. Usage: skelshop idsegs [OPTIONS] REFIN SKELIN FACEIN SEGSOUT Options: --scene-bboxes / --no-scene-bboxes","title":"idsegs"},{"location":"cli/#playsticks","text":"Play a video with stick figures from pose dump superimposed. Usage: skelshop playsticks [OPTIONS] VIDEOIN Options: --skel PATH --face PATH --posetrack / --no-posetrack Whether to convert BODY_25 keypoints to PoseTrack-style keypoints --seek-time FLOAT --seek-frame INTEGER --scale INTEGER --paused / --playing","title":"playsticks"},{"location":"cli/#stats","text":"Output stats about dumps in INPUT_DIR. Usage: skelshop stats [OPTIONS] INPUT_DIR","title":"stats"},{"location":"development/","text":"Please install the pre-commit based git hooks to run black and some basic code checks before submitting a PR. For example: $ pip install --user pre-commit && pre-commit install You can also run them manually at any time: $ ./run-checks.sh In case you make changes, but do not have OpenPose installed, don't forget that you can easily test your changes using Docker, e.g. $ DOCKER_TAG=focal_cpu DOCKERFILE_PATH=Dockerfile IMAGE_NAME=focal_cpu ./hooks/build $ docker run --mount type=bind,source=/,target=/host/ focal_cpu:latest python -m skelshop calibrate process-dlib-dir /host/to/dlib/examples/faces/ /host/to/skelshop/calib.dlib.pqt","title":"Contributing"},{"location":"formats/","text":"The dump format is a HDF5 file: / - Contains metadata attributes such as: fmt_type = unseg | trackshots mode = BODY_25 | BODY_25_ALL | BODY_135 num_frames various version information and command line flag information ... /timeline - Contains shots if trackshots, otherwise if unseg contains poses directly. /timeline/shot0 - A single shot containing poses and with attributes start_frame and end_frame. This interval is closed at the beginning and open and the end, as with Python slices so that num_frames = end_frame - start_frame. /timeline/shot0/pose0 - A CSR sparse matrix[1] stored as a group. Has start_frame and end_frame. The shape of the matrix is (num_frames, limbs, 3). Each element of the matrix is a (x, y, c) tuple directly from OpenPose. CSR sparse matrix on Wikipedia","title":"Formats"},{"location":"io/","text":"Reading and writing the formats from your own code There are tools to read skeletons and face embeddings from your own code. Here is an example of reading from a tracked skeleton file: TODO Reference TODO","title":"Reading and writing the formats from your own code"},{"location":"io/#reading-and-writing-the-formats-from-your-own-code","text":"There are tools to read skeletons and face embeddings from your own code. Here is an example of reading from a tracked skeleton file: TODO","title":"Reading and writing the formats from your own code"},{"location":"io/#reference","text":"TODO","title":"Reference"},{"location":"pipeline-internals/","text":"The stage interface is quite simple. Each stage acts as an iterator, typically yielding some kind of pose bundle. A pose bundle is an iterator of skeletons, either with ids or not depending on whether it has been tracked. Each stage inherits from the PipelineStageBase abstract base class which includes also send_back to send back events to earlier stages in the pipeline. skelshop.pipebase.PipelineStageBase The abstract base class for a pipeline stage. __next__ ( self ) special Get the payload for the next frame Source code in skelshop/pipebase.py @abstractmethod def __next__ ( self ): \"\"\" Get the payload for the next frame \"\"\" ... send_back ( self , name , * args , ** kwargs ) Send a message back down the pipeline by calling a method with name , *args , and `*kwargs Source code in skelshop/pipebase.py def send_back ( self , name : str , * args , ** kwargs ): \"\"\" Send a message back down the pipeline by calling a method with `name`, `*args`, and `*kwargs \"\"\" meth = getattr ( self , name , None ) if meth is not None : meth ( * args , ** kwargs ) return if self . prev is not None : self . prev . send_back ( name , * args , ** kwargs ) Events types in use through send_back Currently cut event is sent back by any shot segmentation stage to the tracking stage, so that tracking can be reset. Each stage is free to deal with events as it wishes, e.g. a tracking stage attempting to track across shots could react differently to this event. A rewind event can be sent back so that a RewindStage will reverse a given number of frames in its buffer. Note that you must arrange for a RewindStage to be placed into the pipeline.","title":"Pipeline internals"},{"location":"pipeline-internals/#skelshop.pipebase.PipelineStageBase","text":"The abstract base class for a pipeline stage.","title":"PipelineStageBase"},{"location":"pipeline-internals/#skelshop.pipebase.PipelineStageBase.__next__","text":"Get the payload for the next frame Source code in skelshop/pipebase.py @abstractmethod def __next__ ( self ): \"\"\" Get the payload for the next frame \"\"\" ...","title":"__next__()"},{"location":"pipeline-internals/#skelshop.pipebase.PipelineStageBase.send_back","text":"Send a message back down the pipeline by calling a method with name , *args , and `*kwargs Source code in skelshop/pipebase.py def send_back ( self , name : str , * args , ** kwargs ): \"\"\" Send a message back down the pipeline by calling a method with `name`, `*args`, and `*kwargs \"\"\" meth = getattr ( self , name , None ) if meth is not None : meth ( * args , ** kwargs ) return if self . prev is not None : self . prev . send_back ( name , * args , ** kwargs )","title":"send_back()"},{"location":"pipeline-internals/#events-types-in-use-through-send_back","text":"Currently cut event is sent back by any shot segmentation stage to the tracking stage, so that tracking can be reset. Each stage is free to deal with events as it wishes, e.g. a tracking stage attempting to track across shots could react differently to this event. A rewind event can be sent back so that a RewindStage will reverse a given number of frames in its buffer. Note that you must arrange for a RewindStage to be placed into the pipeline.","title":"Events types in use through send_back"},{"location":"pipelines-overview/","text":"Skeleton pipeline The overall skeleton pipeline goes like so But note these steps can be left out so we can dump first and do tracking later if we like e.g. first run And then later run Pipelines starting with the pose estimator are run using the dump command, while pipelines starting from existing pose dumps using the filter command. Which method is used for different . See next CLI examples and CLI reference . Face pipeline The face pipeline can run in two modes. In the first mode, which is not recommended for most usages, dlib's face detection and face keypoint detection pipeline is used. There is some information about the dlib keypoint detection in this blog post . In the second mode, an existing pose dump including these 68-keypoints as estimated by OpenPose is used. The second is preferred in most situations. Dlib only pipeline: Skeleton-based pipeline:","title":"Pipelines overview"},{"location":"pipelines-overview/#skeleton-pipeline","text":"The overall skeleton pipeline goes like so But note these steps can be left out so we can dump first and do tracking later if we like e.g. first run And then later run Pipelines starting with the pose estimator are run using the dump command, while pipelines starting from existing pose dumps using the filter command. Which method is used for different . See next CLI examples and CLI reference .","title":"Skeleton pipeline"},{"location":"pipelines-overview/#face-pipeline","text":"The face pipeline can run in two modes. In the first mode, which is not recommended for most usages, dlib's face detection and face keypoint detection pipeline is used. There is some information about the dlib keypoint detection in this blog post . In the second mode, an existing pose dump including these 68-keypoints as estimated by OpenPose is used. The second is preferred in most situations. Dlib only pipeline: Skeleton-based pipeline:","title":"Face pipeline"},{"location":"snakemake/","text":"HPC extraction with Snakemake There are tools for running extraction pipelines orchestrated using Snakemake. These would typically be run in a HPC environment, with GPU nodes orchestrated by SLURM. TODO: Detail","title":"HPC extraction with Snakemake"},{"location":"snakemake/#hpc-extraction-with-snakemake","text":"There are tools for running extraction pipelines orchestrated using Snakemake. These would typically be run in a HPC environment, with GPU nodes orchestrated by SLURM. TODO: Detail","title":"HPC extraction with Snakemake"},{"location":"tracking/","text":"The tracker is a stage that each frame takes an unordered bundle of poses and gives them IDs. skelshop.bbtrack.TrackStage A pipeline stage wrapping the skelshop.track.PoseTrack generic approach to distance-based tracking. Internally it uses the following class, which implements a generic approach to online pose tracking: skelshop.track.track.PoseTrack Performs generic distance-based pose tracking. __init__ ( self , spec ) special Takes a TrackingSpec and constructs the corresponding tracking algorithm. Source code in skelshop/track/track.py def __init__ ( self , spec : TrackingSpec ): \"\"\" Takes a TrackingSpec and constructs the corresponding tracking algorithm. \"\"\" self . next_id = 0 self . prev_tracked : FrameBuf = ( collections . deque ( maxlen = spec . prev_frame_buf_size ) ) self . spec = spec Which is in turn configured using a: skelshop.track.spec.TrackingSpec dataclass A domain specific language for threshold distance-based style tracking. Candidate poses are first filtered using cand_filter and then procedure is executed to decide how to assign the candidates. Several configurations are given in: skelshop.track.confs.CONFS A dictionary of ready-made tracking specs Attributes: Name Type Description \"lighttrackish\" TrackingSpec A LightTrack-like algoirhtm using greedy matching \"opt_lighttrack\" TrackingSpec A LightTrack-like algorithm which attempts to make optimal matches \"deepsortlike\" TrackingSpec A DeepSort-like algorithm (currently missing Kalman filtering) There are references to two systems in the name: LightTrack 1 and DeepSort 2 . The configurations are inspired by these, but not exact implementations. Looking at the implementations in skelshop.track.confs.CONFS is a good starting point for adding new configurations, or extending the tracking, e.g. with a new approach to reidentification. Guanghan Ning, Heng Huang (2019) LightTrack: A Generic Framework for Online Top-Down Human Pose Tracking https://arxiv.org/abs/1905.02822 \u21a9 Nicolai Wojke, Alex Bewley, Dietrich Paulus (2017) Simple Online and Realtime Tracking with a Deep Association Metric https://arxiv.org/abs/1703.07402 \u21a9","title":"Tracking"},{"location":"tracking/#skelshop.bbtrack.TrackStage","text":"A pipeline stage wrapping the skelshop.track.PoseTrack generic approach to distance-based tracking. Internally it uses the following class, which implements a generic approach to online pose tracking:","title":"TrackStage"},{"location":"tracking/#skelshop.track.track.PoseTrack","text":"Performs generic distance-based pose tracking.","title":"PoseTrack"},{"location":"tracking/#skelshop.track.track.PoseTrack.__init__","text":"Takes a TrackingSpec and constructs the corresponding tracking algorithm. Source code in skelshop/track/track.py def __init__ ( self , spec : TrackingSpec ): \"\"\" Takes a TrackingSpec and constructs the corresponding tracking algorithm. \"\"\" self . next_id = 0 self . prev_tracked : FrameBuf = ( collections . deque ( maxlen = spec . prev_frame_buf_size ) ) self . spec = spec Which is in turn configured using a:","title":"__init__()"},{"location":"tracking/#skelshop.track.spec.TrackingSpec","text":"A domain specific language for threshold distance-based style tracking. Candidate poses are first filtered using cand_filter and then procedure is executed to decide how to assign the candidates. Several configurations are given in:","title":"TrackingSpec"},{"location":"tracking/#skelshop.track.confs.CONFS","text":"A dictionary of ready-made tracking specs Attributes: Name Type Description \"lighttrackish\" TrackingSpec A LightTrack-like algoirhtm using greedy matching \"opt_lighttrack\" TrackingSpec A LightTrack-like algorithm which attempts to make optimal matches \"deepsortlike\" TrackingSpec A DeepSort-like algorithm (currently missing Kalman filtering) There are references to two systems in the name: LightTrack 1 and DeepSort 2 . The configurations are inspired by these, but not exact implementations. Looking at the implementations in skelshop.track.confs.CONFS is a good starting point for adding new configurations, or extending the tracking, e.g. with a new approach to reidentification. Guanghan Ning, Heng Huang (2019) LightTrack: A Generic Framework for Online Top-Down Human Pose Tracking https://arxiv.org/abs/1905.02822 \u21a9 Nicolai Wojke, Alex Bewley, Dietrich Paulus (2017) Simple Online and Realtime Tracking with a Deep Association Metric https://arxiv.org/abs/1703.07402 \u21a9","title":"CONFS"},{"location":"usage-examples/","text":"Usage examples Here are some usage examples. There is more help available through the `--help' flag. Modes Mode name Keypoints Body Hands Face BODY_25 25 Yes No No BODY_25_ALL 135 Yes Yes Yes BODY_25_HANDS 65 Yes Yes No FACE 70 No No Yes BODY_25_FACE 95 Yes No Yes Dumping/tracking A working OpenPose install is required for dumping (and only for dumping). We could dump some untracked skeletons with a version of OpenPose we have compiled ourselves like so: LD_LIBRARY_PATH=$OPENPOSE/build/src/openpose/ \\ PYTHONPATH=$OPENPOSE/build/python/ \\ MODEL_FOLDER=$OPENPOSE/models \\ poetry run python -m skelshop \\ dump \\ --mode BODY_25 \\ video_in.mp4 pose_data.h5 We could also use the Singularity image. OpenPose is installed in the image and everything is setup up for us so we can just run: $ singularity exec --nv skelshop.sif python /opt/skelshop/skelshop dump video_in.mp4 pose_data.h5 If the host machine does not have CUDA, then --nv can be omitted and the container will automatically select the CPU version of OpenPose instead. You can track an existing dump using the filter command with the --track flag or apply tracking at the same time as dumping. Currently scene segmentation is expected in this case, which can be done using CSV dumps generated with PySceneDetect's CLI . For more information see the Snakefile , and the help provided with python skelshop --help . Conversion Convert from a zip file containing files named like so: XXXXXXX_0000000NNNNN_keypoints.json $ poetry run python skelshop conv Convert from a tar file containing similarly name files in order : $ poetry run python skelshop conv Drawing/playing Play a video with sticks superimposed (without sound): $ poetry run python skelshop playsticks pose_data.h5 video_in.mp4 video_out.mp4 Press h/? to see the keyboard controls available in the player. Dump a video with sticks superimposed (without sound): $ poetry run python skelshop drawsticks pose_data.h5 video_in.mp4 video_out.mp4","title":"Usage examples"},{"location":"usage-examples/#usage-examples","text":"Here are some usage examples. There is more help available through the `--help' flag.","title":"Usage examples"},{"location":"usage-examples/#modes","text":"Mode name Keypoints Body Hands Face BODY_25 25 Yes No No BODY_25_ALL 135 Yes Yes Yes BODY_25_HANDS 65 Yes Yes No FACE 70 No No Yes BODY_25_FACE 95 Yes No Yes","title":"Modes"},{"location":"usage-examples/#dumpingtracking","text":"A working OpenPose install is required for dumping (and only for dumping). We could dump some untracked skeletons with a version of OpenPose we have compiled ourselves like so: LD_LIBRARY_PATH=$OPENPOSE/build/src/openpose/ \\ PYTHONPATH=$OPENPOSE/build/python/ \\ MODEL_FOLDER=$OPENPOSE/models \\ poetry run python -m skelshop \\ dump \\ --mode BODY_25 \\ video_in.mp4 pose_data.h5 We could also use the Singularity image. OpenPose is installed in the image and everything is setup up for us so we can just run: $ singularity exec --nv skelshop.sif python /opt/skelshop/skelshop dump video_in.mp4 pose_data.h5 If the host machine does not have CUDA, then --nv can be omitted and the container will automatically select the CPU version of OpenPose instead. You can track an existing dump using the filter command with the --track flag or apply tracking at the same time as dumping. Currently scene segmentation is expected in this case, which can be done using CSV dumps generated with PySceneDetect's CLI . For more information see the Snakefile , and the help provided with python skelshop --help .","title":"Dumping/tracking"},{"location":"usage-examples/#conversion","text":"Convert from a zip file containing files named like so: XXXXXXX_0000000NNNNN_keypoints.json $ poetry run python skelshop conv Convert from a tar file containing similarly name files in order : $ poetry run python skelshop conv","title":"Conversion"},{"location":"usage-examples/#drawingplaying","text":"Play a video with sticks superimposed (without sound): $ poetry run python skelshop playsticks pose_data.h5 video_in.mp4 video_out.mp4 Press h/? to see the keyboard controls available in the player. Dump a video with sticks superimposed (without sound): $ poetry run python skelshop drawsticks pose_data.h5 video_in.mp4 video_out.mp4","title":"Drawing/playing"}]}